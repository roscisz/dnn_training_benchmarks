diff --git a/dcgan/main.py b/dcgan/main.py
index 9d5369c..e71e1f0 100644
--- a/dcgan/main.py
+++ b/dcgan/main.py
@@ -2,8 +2,8 @@ from __future__ import print_function
 import argparse
 import os
 import random
+import time
 import torch
-import torch.nn as nn
 import torch.nn.parallel
 import torch.backends.cudnn as cudnn
 import torch.optim as optim
@@ -11,11 +11,21 @@ import torch.utils.data
 import torchvision.datasets as dset
 import torchvision.transforms as transforms
 import torchvision.utils as vutils
+from torch import distributed, nn
 
 
 parser = argparse.ArgumentParser()
+parser.add_argument('--backend', type=str, default='gloo', help='Name of the backend to use.')
+parser.add_argument(
+    '-i',
+    '--init-method',
+    type=str,
+    default='tcp://127.0.0.1:23456',
+    help='URL specifying how to initialize the package.')
+parser.add_argument('-s', '--world-size', type=int, default=1, help='Number of processes participating in the job.')
+parser.add_argument('-r', '--rank', type=int, default=0, help='Rank of the current process.')
 parser.add_argument('--dataset', required=True, help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')
-parser.add_argument('--dataroot', required=True, help='path to dataset')
+parser.add_argument('--dataroot', required=False, help='path to dataset')
 parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)
 parser.add_argument('--batchSize', type=int, default=64, help='input batch size')
 parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')
@@ -36,6 +46,14 @@ parser.add_argument('--classes', default='bedroom', help='comma separated list o
 opt = parser.parse_args()
 print(opt)
 
+if opt.world_size > 1:
+        distributed.init_process_group(
+            backend=opt.backend,
+            init_method=opt.init_method,
+            world_size=opt.world_size,
+            rank=opt.rank,
+        )
+
 try:
     os.makedirs(opt.outf)
 except OSError:
@@ -96,8 +114,11 @@ elif opt.dataset == 'fake':
     nc=3
 
 assert dataset
+sampler = None
+if opt.world_size > 1:
+    sampler = torch.utils.data.DistributedSampler(dataset)
 dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,
-                                         shuffle=True, num_workers=int(opt.workers))
+                                         shuffle=(sampler is None), num_workers=int(opt.workers), sampler=sampler)
 
 device = torch.device("cuda:0" if opt.cuda else "cpu")
 ngpu = int(opt.ngpu)
@@ -155,6 +176,8 @@ netG = Generator(ngpu).to(device)
 netG.apply(weights_init)
 if opt.netG != '':
     netG.load_state_dict(torch.load(opt.netG))
+if opt.world_size > 1:
+    netG = nn.parallel.DistributedDataParallel(netG)
 print(netG)
 
 
@@ -196,6 +219,8 @@ netD = Discriminator(ngpu).to(device)
 netD.apply(weights_init)
 if opt.netD != '':
     netD.load_state_dict(torch.load(opt.netD))
+if opt.world_size > 1:
+    netD = nn.parallel.DistributedDataParallel(netD)
 print(netD)
 
 criterion = nn.BCELoss()
@@ -209,6 +234,7 @@ optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
 optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
 
 for epoch in range(opt.niter):
+    start = time.time()
     for i, data in enumerate(dataloader, 0):
         ############################
         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
@@ -245,10 +271,10 @@ for epoch in range(opt.niter):
         errG.backward()
         D_G_z2 = output.mean().item()
         optimizerG.step()
-
         print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'
               % (epoch, opt.niter, i, len(dataloader),
                  errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
+
         if i % 100 == 0:
             vutils.save_image(real_cpu,
                     '%s/real_samples.png' % opt.outf,
@@ -257,7 +283,9 @@ for epoch in range(opt.niter):
             vutils.save_image(fake.detach(),
                     '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),
                     normalize=True)
-
+            end = time.time()
+            print("Time per 100 iterations: " + round(str(end - start), 3) + " s")
+            start = time.time()
     # do checkpointing
     torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))
     torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))
